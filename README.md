# ğŸ§  The Gardner Capacity Puzzle
### *Numerical Investigation of Perceptron Storage Capacity*

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![arXiv](https://img.shields.io/badge/arXiv-Statistical_Physics-red.svg)](https://arxiv.org)
[![Code Style](https://img.shields.io/badge/Code%20Style-Black-black.svg)](https://black.readthedocs.io)

> *"A fascinating mathematical puzzle where a flawed derivation yields the correct answer due to hidden symmetries in high-dimensional statistics."*

## ğŸ¯ Overview

This project explores the **Gardner problem**: determining the storage capacity of a simple perceptron with margin constraints. We investigate a remarkable "puzzle" from statistical physics where a naÃ¯ve mathematical derivation contains an internal contradiction yet produces the correct final answer.

**Central Question:** What is the maximum ratio `Î± = P/N` of data points to dimensions that a perceptron can separate with a given margin?

## ğŸ“Š Visual Results

### Phase Transition Visualization
![Gardner Capacity Phase Transition](gardner_capacity_N100_kappa1.0.png)

*Figure 1: Sharp phase transition at Î±_c = 0.5 for Îº = 1.0. The blue curve shows numerical simulation results, while the red dashed line indicates the theoretical prediction.*

### Key Findings
- **Sharp transition** at the theoretical critical capacity Î±_c = 0.5
- **Perfect agreement** between flawed theory and numerical simulation  
- **Success rate**: 100% below Î±_c, 0% above Î±_c

## ğŸ”¬ Theoretical Analysis

### Problem Formulation
Find weight vector **w** âˆˆ â„â¿ satisfying:

```math
\begin{align}
\mathbf{w} \cdot \mathbf{x}_\mu &\geq \kappa \quad \forall \mu = 1, \ldots, P \\
\|\mathbf{w}\|^2 &= N
\end{align}
```

Where:
- **P**: Number of random data points  
- **N**: Dimensionality of the space
- **Îº**: Margin parameter
- **Î± = P/N**: Storage capacity ratio

### ğŸ§® The "NaÃ¯ve" Derivation

Starting from the critical relationship:

```math
\alpha^{-1} = \langle(\kappa - z)^2\rangle_z \quad \text{where } z \sim \mathcal{N}(0,1)
```

**Step-by-step calculation:**
1. Expand: `(Îº - z)Â² = ÎºÂ² - 2Îºz + zÂ²`
2. Take expectation: `âŸ¨ÎºÂ² - 2Îºz + zÂ²âŸ© = ÎºÂ² - 2ÎºâŸ¨zâŸ© + âŸ¨zÂ²âŸ©`  
3. Apply properties: `âŸ¨zâŸ© = 0`, `âŸ¨zÂ²âŸ© = 1`
4. Result: `âŸ¨(Îº - z)Â²âŸ© = ÎºÂ² + 1`

### ğŸ¯ Critical Capacity Formula

```math
\boxed{\alpha_c(\kappa) = \frac{1}{\kappa^2 + 1}}
```

For **Îº = 1**: `Î±_c = 0.5` â† *This is what our simulation validates!*

### âš ï¸ The Mathematical Paradox

The derivation uses **two contradictory approaches** to calculate `||w||Â²`:

| Method | Equation | Assumption |
|--------|----------|------------|
| **NaÃ¯ve Statistical** | `1/ÎºÂ² = Î± âŸ¨Î»_Î¼Â²âŸ©` | Independence + disorder averaging |
| **Direct KKT-based** | `1/ÎºÂ² = Î± âŸ¨Î»_Î¼âŸ©` | Direct constraint application |

**The Contradiction:** These require `âŸ¨Î»_Î¼âŸ© = âŸ¨Î»_Î¼Â²âŸ©`, which violates basic probability theory!

**The Miracle:** Despite being mathematically flawed, the naÃ¯ve method produces the *exact* correct answer due to a hidden symmetry in the Gardner problem.

## ğŸ’» Implementation

### ğŸ—ï¸ Project Architecture
```
gardner-capacity-puzzle/
â”œâ”€â”€ ğŸ“„ main.py                    # ğŸ¯ Main simulation orchestrator
â”œâ”€â”€ ğŸ§® simulation.py              # ğŸ”§ Core Gardner problem solver  
â”œâ”€â”€ ğŸ“Š analysis.py                # ğŸ“ˆ Visualization & plotting
â”œâ”€â”€ ğŸ“‹ requirements.txt           # ğŸ“¦ Python dependencies
â”œâ”€â”€ ğŸ–¼ï¸ gardner_capacity_*.png     # ğŸ“Š Generated phase transition plots
â””â”€â”€ ğŸ“– README.md                  # ğŸ“š This documentation
```

### ğŸ”§ Technical Implementation

Our solution uses **constrained optimization** instead of traditional SVM approaches:

```python
# Core algorithm: Maximize minimum margin subject to ||w||Â² = N
def solve_gardner_problem(X, kappa, N):
    """
    Solves: max_w min_Î¼ (wÂ·x_Î¼) subject to ||w||Â² = N
    Returns: True if achievable margin â‰¥ kappa
    """
    # Method 1: Constrained optimization with scipy
    # Method 2: Random projection fallback
```

**Why not SVM?** Traditional SVMs require multiple classes, but Gardner problem has uniform constraints.

### ğŸš€ Quick Start

#### Prerequisites
- Python 3.8+
- Virtual environment (recommended)

#### Installation & Execution
```bash
# Clone the repository
git clone https://github.com/Sakeeb91/gardner-capacity-puzzle.git
cd gardner-capacity-puzzle

# Set up environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run simulation
python main.py
```

#### Expected Output
```
Parameters: N=100, kappa=1.0, num_trials=20
Theoretical critical capacity alpha_c = 0.5000
Simulating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [01:17<00:00, 3.85s/it]
```

## ğŸ“ˆ Results Interpretation

### Phase Transition Characteristics

| Î± Range | Success Rate | Physical Interpretation |
|---------|-------------|------------------------|
| Î± < 0.4 | ~100% | **Feasible regime**: Easy to find solutions |
| Î± â‰ˆ 0.5 | ~50% | **Critical point**: Phase transition |  
| Î± > 0.6 | ~0% | **Impossible regime**: No solutions exist |

### Simulation Parameters
- **N = 100**: Dimensionality (sufficient for sharp transition)
- **Îº = 1.0**: Margin parameter  
- **20 trials per Î±**: Statistical averaging
- **Î± âˆˆ [0.2, 0.8]**: Range around critical point

## ğŸ¯ Key Insights

### ğŸ”® The Statistical Physics Miracle

This project reveals a profound phenomenon in theoretical physics:

> **"Sometimes mathematical errors lead to correct physical predictions due to hidden symmetries in the problem structure."**

#### Why This Matters:
1. **Pedagogical Value**: Demonstrates the subtlety of high-dimensional statistics
2. **Historical Significance**: Classic example from the replica method literature  
3. **Methodological Lesson**: Shows limitations of naÃ¯ve statistical approaches
4. **Physical Intuition**: Phase transitions are universal in complex systems

### ğŸ§¬ Connection to Modern ML

The Gardner capacity relates to fundamental questions in machine learning:
- **Generalization bounds** in high-dimensional spaces
- **Double descent** phenomena in overparameterized models  
- **Phase transitions** in neural network training dynamics

## ğŸ¤ Contributing

We welcome contributions! Areas for enhancement:

- [ ] **Multi-Îº analysis**: Explore different margin parameters
- [ ] **Finite-size scaling**: Study N-dependence of transition width
- [ ] **Alternative algorithms**: Compare optimization methods
- [ ] **Theoretical extensions**: Implement rigorous cavity method
- [ ] **Interactive visualization**: Add plotly/bokeh interfaces

## ğŸ“š References & Further Reading

- **Original Paper**: "Simplified derivations for high-dimensional convex learning problems"
- **Statistical Physics**: MÃ©zard, Parisi & Virasoro - "Spin Glass Theory"  
- **Modern ML Connection**: Bahri et al. - "Statistical Mechanics of Deep Learning"

## ğŸ“„ License

MIT License - feel free to use this for research and educational purposes!

---

<div align="center">


*Exploring the beautiful intersection of statistical physics and machine learning*

[![GitHub stars](https://img.shields.io/github/stars/Sakeeb91/gardner-capacity-puzzle?style=social)](https://github.com/Sakeeb91/gardner-capacity-puzzle)

</div>
